# -*- coding: utf-8 -*-
"""LFD Assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nI8LFfzor9YAQE2U6Y2m-xpKz2jryMLE
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_roc_curve,roc_curve, roc_auc_score
from sklearn import metrics
import keras
from keras.models import Sequential
from keras.layers import Dense
import pandas as pd
import matplotlib.pyplot as plt
 
bank_info=pd.read_csv('/bill_authentication.csv')

 
bank_info.columns =['variance', 'skewness ', 'curtosis ', 'entropy ','class']
bank_info = bank_info.drop_duplicates()
bank_info.describe()

#divide data into input "x" and output"y"
y = bank_info['class']
x =bank_info.drop(['class'],axis = 1)
x,y

#divide data set into trainning and testing sets with testing size on 30 percentage
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)

standardizingScaler = StandardScaler()
x_train = standardizingScaler.fit_transform(x_train)
x_test = standardizingScaler.transform(x_test)

#Multi layer neuorn network archticture.
classification = Sequential()

#classification Layer number one with 4 neuorns.
classification.add(Dense(4, activation='sigmoid', kernel_initializer='uniform',input_dim=4))

#classification Layer number two with 4 neuorns.
classification.add(Dense(4, activation = 'sigmoid', kernel_initializer = 'uniform'))

#classification Layer number three with 1 neuorns.
classification.add(Dense(1, activation = 'sigmoid', kernel_initializer = 'uniform'))

#initialization of the weights of network lyers

#Layer 1
layer_one_w = classification.layers[0].get_weights()[0]
layer_one_b  = classification.layers[0].get_weights()[1] #baise layer 1
#Layer 2
layer_two_w = classification.layers[1].get_weights()[0]
layer_two_b  =classification.layers[1].get_weights()[1] #baise layer 2
#Layer 3
layer_three_w = classification.layers[2].get_weights()[0]
layer_three_b  =classification.layers[2].get_weights()[1] #baise layer 3

#initialization weights layer one 
intial_layer1_w = pd.DataFrame(columns=['input1,1','input1,2','input1,3','input1,4','bais1'])
intial_layer1_w['input1,1']=layer_one_w.tolist()[0]
intial_layer1_w['input1,2']=layer_one_w.tolist()[1]
intial_layer1_w['input1,3']=layer_one_w.tolist()[2]
intial_layer1_w['input1,4']=layer_one_w.tolist()[3]
intial_layer1_w['bais1']=layer_one_b.tolist()

#initialization weights layer two 
intial_layer2_w = pd.DataFrame(columns=['input2,1','input2,2','input2,3','input2,4','bais2'])
intial_layer2_w['input2,1']=layer_two_w.tolist()[0]
intial_layer2_w['input2,2']=layer_two_w.tolist()[1]
intial_layer2_w['input2,3']=layer_two_w.tolist()[2]
intial_layer2_w['input2,4']=layer_two_w.tolist()[3]
intial_layer2_w['bais2']=layer_two_b.tolist()

#initialization weights layer three 
initial_layer3_w = pd.DataFrame(columns=['input3','bais3'])
initial_layer3_w['input3']=layer_three_w.tolist()[0]
initial_layer3_w['bais3']=layer_three_b.tolist()

classification.compile(optimizer = 'adam', loss = 'binary_crossentropy',  metrics=['accuracy'])
training_accuracy = []
testing_accuracy = []
training_error = []
testing_error = []

intial_layer1_w

intial_layer2_w

initial_layer3_w

# evaluate the performance of perceptron network With runnig 50 epochs of training on the training set.
for i in range(0,50):
  classification.fit(x_train, y_train, batch_size = 10)
 
  y_train_pred = classification.predict(x_train)
  y_train_pred = (y_train_pred > 0.5)
 
  y_test_pred = classification.predict(x_test)
  y_test_pred = (y_test_pred > 0.5)
 
  y_train_predicted = pd.DataFrame(y_train_pred)
  y_test_predicted = pd.DataFrame(y_test_pred)
 
  training_accuracy.append(accuracy_score(y_train_predicted, y_train))
 
  testing_accuracy.append(accuracy_score(y_test_predicted, y_test))
 
  training_error.append(1-training_accuracy[i])
  testing_error.append(1-testing_accuracy[i])

#Final weights
layer_one_final_w = classification.layers[0].get_weights()[0]
layer_one_final_b  = classification.layers[0].get_weights()[1]
layer_two_final_w = classification.layers[1].get_weights()[0]
layer_two_final_b  =classification.layers[1].get_weights()[1]
layer_three_final_w = classification.layers[2].get_weights()[0]
layer_three_final_b  =classification.layers[2].get_weights()[1]

#First layer final weights
final_w1 = pd.DataFrame(columns=['in1,1','in1,2','in1,3','in1,4','b1'])
final_w1['in1,1']=layer_one_final_w.tolist()[0]
final_w1['in1,2']=layer_one_final_w.tolist()[1]
final_w1['in1,3']=layer_one_final_w.tolist()[2]
final_w1['in1,4']=layer_one_final_w.tolist()[3]
final_w1['b1']=layer_one_final_b.tolist()

#Second final weights
final_w2= pd.DataFrame(columns=['in2,1','in2,2','in2,3','in2,4','b2'])
final_w2['in2,1']=layer_two_final_w.tolist()[0]                           
final_w2['in2,2']=layer_two_final_w.tolist()[1]
final_w2['in2,3']=layer_two_final_w.tolist()[2]
final_w2['in2,4']=layer_two_final_w.tolist()[3]
final_w2['b2']=layer_two_final_b.tolist()

#Third layer initial weights
final_w3= pd.DataFrame(columns=['in3','b3'])
final_w3['in3']=layer_three_w.tolist()[0]
final_w3['b3']=layer_three_b.tolist()

final_w1

final_w2

final_w3

confusion_matrix= metrics.confusion_matrix(y_test,  y_test_pred)
print(confusion_matrix)

accuracy_percentage= (confusion_matrix[0,0]+confusion_matrix[1,1])/sum(sum(confusion_matrix))*100
print(accuracy_percentage)

confusion_matrix_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
confusion_matrix_display.plot()
plt.show()

print(metrics.classification_report(y_test,y_test_predicted))

plt.plot(training_accuracy,label = "Training Accuracy")
plt.plot(testing_accuracy, label = "Testing Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy%')
plt.show()

plt.plot(training_error,label = "Training Error")
plt.plot(testing_error, label = "Testing Error")
plt.xlabel('Epochs')
plt.ylabel('Error%')
plt.show()

false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_test_predicted)
plt.plot(false_positive_rate, true_positive_rate)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()